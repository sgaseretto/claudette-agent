{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# claudette-agent Examples\n",
    "\n",
    "This notebook demonstrates all the features of `claudette-agent`, a Claude Agent SDK wrapper with a Claudette-compatible API.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Make sure you have `claude-agent-sdk` installed and configured with your Claude Code subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed (uncomment)\n",
    "# !pip install claude-agent-sdk pydantic\n",
    "\n",
    "# Import the package\n",
    "from claudette_agent import (\n",
    "    Chat, AsyncChat, Client,\n",
    "    contents, query, tool,\n",
    "    MCPToolkit, mcp_tool, create_mcp_server,\n",
    "    Usage, Message, TextBlock\n",
    ")\n",
    "\n",
    "# Default model to use\n",
    "MODEL = \"claude-sonnet-4-5-20250929\"\n",
    "\n",
    "print(\"claudette-agent loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-chat-header",
   "metadata": {},
   "source": [
    "## 1. Basic Chat\n",
    "\n",
    "The `Chat` class maintains conversation history and supports system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat with a system prompt\n",
    "chat = Chat(model=MODEL, sp=\"You are a helpful assistant. Be concise.\")\n",
    "\n",
    "# Send a message\n",
    "response = await chat(\"What is the capital of France?\")\n",
    "print(\"Response:\", contents(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-followup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation - Claude remembers the context\n",
    "response = await chat(\"What is its population?\")\n",
    "print(\"Follow-up:\", contents(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View conversation history\n",
    "print(f\"History length: {len(chat.h)} messages\")\n",
    "for i, msg in enumerate(chat.h):\n",
    "    role = msg.get('role', 'unknown')\n",
    "    content = msg.get('content', [])\n",
    "    if isinstance(content, list) and content:\n",
    "        text = content[0].get('text', '')[:50]\n",
    "    else:\n",
    "        text = str(content)[:50]\n",
    "    print(f\"  {i+1}. [{role}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-query-header",
   "metadata": {},
   "source": [
    "## 2. Simple Query (No History)\n",
    "\n",
    "Use `query()` for one-shot queries without conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one-shot query\n",
    "response = await query(\"What is 2 + 2?\", model=MODEL)\n",
    "print(\"Answer:\", contents(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-header",
   "metadata": {},
   "source": [
    "## 3. Using Tools\n",
    "\n",
    "Define tools using the `@tool` decorator and pass them to `Chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-define",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression safely.\"\"\"\n",
    "    # Simple calculator - only allow safe operations\n",
    "    allowed = set('0123456789+-*/(). ')\n",
    "    if all(c in allowed for c in expression):\n",
    "        return str(eval(expression))\n",
    "    return \"Error: Invalid expression\"\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"paris\": \"Sunny, 22째C\",\n",
    "        \"london\": \"Cloudy, 15째C\",\n",
    "        \"tokyo\": \"Rainy, 18째C\",\n",
    "        \"new york\": \"Clear, 25째C\",\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not available for {city}\")\n",
    "\n",
    "print(\"Tools defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-use",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat with tools\n",
    "chat_with_tools = Chat(\n",
    "    model=MODEL,\n",
    "    sp=\"You are a helpful assistant with access to a calculator and weather service.\",\n",
    "    tools=[calculate, get_weather]\n",
    ")\n",
    "\n",
    "# Ask a math question\n",
    "response = await chat_with_tools(\"What is 15 * 23 + 7?\")\n",
    "print(\"Math answer:\", contents(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about weather\n",
    "response = await chat_with_tools(\"What's the weather in Paris?\")\n",
    "print(\"Weather:\", contents(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toolloop-header",
   "metadata": {},
   "source": [
    "## 4. Tool Loop (Automatic Tool Following)\n",
    "\n",
    "Use `toolloop()` to automatically follow up on tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toolloop",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"Search a database for information.\"\"\"\n",
    "    # Simulated search results\n",
    "    results = {\n",
    "        \"python\": \"Python is a high-level programming language known for its simplicity.\",\n",
    "        \"async\": \"Async programming allows concurrent execution without threads.\",\n",
    "        \"ai\": \"AI is the simulation of human intelligence by machines.\",\n",
    "    }\n",
    "    for key, value in results.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return \"No results found.\"\n",
    "\n",
    "# Create chat with search tool\n",
    "research_chat = Chat(\n",
    "    model=MODEL,\n",
    "    sp=\"You are a research assistant. Use the search tool to find information.\",\n",
    "    tools=[search_database]\n",
    ")\n",
    "\n",
    "# Run toolloop - automatically follows tool calls\n",
    "results = await research_chat.toolloop(\n",
    "    \"Search for information about Python and summarize it.\",\n",
    "    max_steps=3\n",
    ")\n",
    "\n",
    "print(\"Toolloop results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n--- Step {i+1} ---\")\n",
    "    print(contents(result)[:200] + \"...\" if len(contents(result)) > 200 else contents(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-header",
   "metadata": {},
   "source": [
    "## 5. Structured Outputs with Pydantic\n",
    "\n",
    "Use `chat.struct()` to get responses as Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-define",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"The person's full name\")\n",
    "    age: int = Field(description=\"The person's age in years\")\n",
    "    occupation: str = Field(description=\"The person's job or profession\")\n",
    "    hobbies: Optional[List[str]] = Field(default=None, description=\"List of hobbies\")\n",
    "\n",
    "print(\"Pydantic model defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-use",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat for structured extraction\n",
    "struct_chat = Chat(model=MODEL)\n",
    "\n",
    "# Extract structured data\n",
    "person = await struct_chat.struct(\n",
    "    \"Extract the person info: John Smith is a 35-year-old software engineer who enjoys hiking and photography.\",\n",
    "    Person\n",
    ")\n",
    "\n",
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Age: {person.age}\")\n",
    "print(f\"Occupation: {person.occupation}\")\n",
    "print(f\"Hobbies: {person.hobbies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex structured output\n",
    "class Recipe(BaseModel):\n",
    "    \"\"\"A cooking recipe.\"\"\"\n",
    "    name: str\n",
    "    ingredients: List[str]\n",
    "    steps: List[str]\n",
    "    prep_time_minutes: int\n",
    "    difficulty: str\n",
    "\n",
    "recipe_chat = Chat(model=MODEL)\n",
    "recipe = await recipe_chat.struct(\n",
    "    \"Create a simple pasta recipe with tomato sauce.\",\n",
    "    Recipe\n",
    ")\n",
    "\n",
    "print(f\"Recipe: {recipe.name}\")\n",
    "print(f\"Prep time: {recipe.prep_time_minutes} minutes\")\n",
    "print(f\"Difficulty: {recipe.difficulty}\")\n",
    "print(f\"\\nIngredients:\")\n",
    "for ing in recipe.ingredients:\n",
    "    print(f\"  - {ing}\")\n",
    "print(f\"\\nSteps:\")\n",
    "for i, step in enumerate(recipe.steps, 1):\n",
    "    print(f\"  {i}. {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-header",
   "metadata": {},
   "source": "## 6. Streaming Responses\n\nUse `chat.stream()` to get responses as they're generated.\n\n**Important:** The Claude Agent SDK streams complete message blocks, not individual text characters like the Anthropic API. Each yielded value is a complete text block from Claude's response."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming",
   "metadata": {},
   "outputs": [],
   "source": "# Create a chat for streaming\nstream_chat = Chat(model=MODEL, sp=\"You are a storyteller. Tell engaging short stories.\")\n\nprint(\"Streaming response (note: SDK yields message blocks, not characters):\\n\")\nasync for block in stream_chat.stream(\"Tell me a very short story about a robot learning to paint.\"):\n    print(block, end=\"\", flush=True)\n\nprint(\"\\n\\n--- Done! ---\")"
  },
  {
   "cell_type": "markdown",
   "id": "cost-header",
   "metadata": {},
   "source": [
    "## 7. Cost Tracking\n",
    "\n",
    "Track token usage and estimated costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cost-tracking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chat to track usage\n",
    "tracked_chat = Chat(model=MODEL)\n",
    "\n",
    "# Make several requests\n",
    "await tracked_chat(\"What is Python?\")\n",
    "await tracked_chat(\"What are its main uses?\")\n",
    "await tracked_chat(\"Give me a simple code example.\")\n",
    "\n",
    "# Check usage statistics\n",
    "print(\"Usage Statistics:\")\n",
    "print(f\"  Input tokens: {tracked_chat.use.input_tokens:,}\")\n",
    "print(f\"  Output tokens: {tracked_chat.use.output_tokens:,}\")\n",
    "print(f\"  Total tokens: {tracked_chat.use.total:,}\")\n",
    "print(f\"  Estimated cost: ${tracked_chat.cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client-header",
   "metadata": {},
   "source": [
    "## 8. Low-Level Client\n",
    "\n",
    "Use `Client` directly for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "client-use",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "client = Client(model=MODEL)\n",
    "\n",
    "# Make a direct call\n",
    "response = await client(\n",
    "    msgs=\"Explain quantum computing in one sentence.\",\n",
    "    sp=\"You are a physics professor. Be concise.\",\n",
    "    maxtok=100\n",
    ")\n",
    "\n",
    "print(\"Response:\", contents(response))\n",
    "print(f\"\\nTokens used: {client.use.total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-header",
   "metadata": {},
   "source": [
    "## 9. MCP Server Integration (Advanced)\n",
    "\n",
    "Create and use MCP servers for complex tool integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MCP tools\n",
    "@mcp_tool(\"add\", \"Add two numbers\", {\"a\": float, \"b\": float})\n",
    "async def add_numbers(args):\n",
    "    result = args['a'] + args['b']\n",
    "    return {\"content\": [{\"type\": \"text\", \"text\": str(result)}]}\n",
    "\n",
    "@mcp_tool(\"multiply\", \"Multiply two numbers\", {\"a\": float, \"b\": float})\n",
    "async def multiply_numbers(args):\n",
    "    result = args['a'] * args['b']\n",
    "    return {\"content\": [{\"type\": \"text\", \"text\": str(result)}]}\n",
    "\n",
    "# Note: Full MCP server usage requires the claude-agent-sdk to be properly configured\n",
    "# This example shows the API but may not run without full SDK setup\n",
    "print(\"MCP tools defined!\")\n",
    "print(\"Note: Full MCP functionality requires claude-agent-sdk configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "1. **Basic Chat** - `Chat` class with conversation history\n",
    "2. **Simple Query** - `query()` for one-shot requests\n",
    "3. **Tools** - `@tool` decorator for function calling\n",
    "4. **Tool Loop** - `toolloop()` for automatic tool following\n",
    "5. **Structured Outputs** - `struct()` with Pydantic models\n",
    "6. **Streaming** - `stream()` for real-time responses\n",
    "7. **Cost Tracking** - `use` and `cost` properties\n",
    "8. **Client** - Low-level `Client` class\n",
    "9. **MCP** - Model Context Protocol integration\n",
    "\n",
    "For more information, see the [README](./README.md) and the [claude-agent-sdk documentation](https://github.com/anthropics/claude-agent-sdk-python)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}